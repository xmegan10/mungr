advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (card_perc < .5){
warning(sprintf("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %d of your values are unique. This looks like an ID or free text, not a categorical factor.", card_perc))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %.2f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.2f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (card_perc < .5){
warning(sprintf("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %d of your values are unique. This looks like an ID or free text, not a categorical factor.", card_perc))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %.1f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (card_perc < .5){
warning(sprintf("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %d of your values are unique. This looks like an ID or free text, not a categorical factor.", card_perc))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector, card_perc = .3)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %.1f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (card_perc < .5){
warning(cat("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %d of your values are unique. This looks like an ID or free text, not a categorical factor.", card_perc))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector, card_perc = .3)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
if (card_perc < .5){
warning(cat("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %.1f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %d of your values are unique. This looks like an ID or free text, not a categorical factor.", card_perc))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector, card_perc = .3)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
if (card_perc < .5){
warning(cat("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %.1f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %.1f%% of your values are unique. This looks like an ID or free text, not a categorical factor.", (card_perc)*100))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector, card_perc = .3)
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
if (card_perc < .5){
warning(cat("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %.1f%% of your values are unique. This looks like an ID or free text, not a categorical factor.", (card_perc)*100))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
setMethod("give_advice","MungrInspector", function(object, na_threshold = .5, card_perc = .9) {
df <- object@df
n_rows <- nrow(df)
issues_found <- FALSE
if (card_perc < .5){
warning(cat("Your cardinality percentage is low. You might want to try setting one that is at least 70%."))
}
for(col_name in names(df)){
col_data <- df[[col_name]]
advice_list <- character()
#Check Missing Data Severity
n_na <- object@na_counts[col_name]
if(n_na >0){
percentage_is_na <- (n_na/n_rows) * 100
if(percentage_is_na > na_threshold){
advice_list <- c(advice_list, sprintf("CRITICAL: %f%% missing. Consider dropping this column.", percentage_is_na))
}else{
advice_list <- c(advice_list, sprintf("Warning: %.1f%% missing. Consider imputing missing values with mean or mode.", percentage_is_na))
}
}
#Check empty strings (characters only)
if (is.character(col_data)) {
n_empty <- object@empty_counts[col_name]
if (n_empty > 0) {
advice_list <- c(advice_list, "Consistency Issue: Mixed empty strings and NAs. Replace empty strings with this code: df[df == ''] <- NA")
}
# Check Case Sensitivity
# If we lower-case everything, do we have fewer unique items? e.g., "Male", "male" -> "male" (2 items becomes 1)
n_uniq_original <- length(unique(col_data))
n_uniq_lower <- length(unique(tolower(col_data)))
if (n_uniq_lower < n_uniq_original) {
diff <- n_uniq_original - n_uniq_lower
advice_list <- c(advice_list, sprintf("Formatting issue: Case inconsistency detected (%d duplicates). You have the same values counted as unique from each other due to case sensitivity. If this is not intentional, run: toupper() or tolower()", diff))
}
#Check for High Cardinality (Too many categories)
# If a high percentage (card_perc) of the rows are unique, it's likely an ID or free text, not a category
if (n_uniq_original > (n_rows * card_perc) && n_uniq_original < n_rows) {
advice_list <- c(advice_list, sprintf("Datatype: There's a lot of unique categories; %.1f%% of your values are unique. This looks like an ID or free text, not a categorical factor.", (card_perc)*100))
}
}
#Check for Zero Variance (Useless column)
# If there is only 1 unique value (and it's not just all NAs)
if (length(unique(na.omit(col_data))) == 1) {
advice_list <- c(advice_list, "Redundancy: Column has zero variance (same value for entire column). You might want to drop it.")
}
#Final results
if (length(advice_list) > 0) {
issues_found <- TRUE
cat(sprintf("Column [%s]:\n", col_name))
# Print advice with a bullet point
cat(sprintf("  -> %s", advice_list), sep = "\n")
cat("\n")
}
} #end of for loop
if (!issues_found) {
cat("No obvious data issues found. Good job!\n")
}
})
dirty_df <- data.frame(
ID = c("A1", "A2", "A3", "A4", "A5"),          # High Cardinality (OK for ID, but we might warn)
Gender = c("Male", "male", "Female", "F", NA),  # Case inconsistency + NAs
Country = c("USA", "USA", "USA", "USA", "USA"), # Zero Variance
Notes = c("ok", "", "bad", NA, ""),             # Mixed Empty/NA
stringsAsFactors = FALSE
)
# 2. Create Object
inspector <- MungrInspector(dirty_df)
# 3. Ask for advice
give_advice(inspector, card_perc = .3)
